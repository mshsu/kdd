{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CSC 466: Knowledge Discovery in Data**\n",
    "\n",
    "**Individual Test**\n",
    "\n",
    "**Task 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Name :**\n",
    "\n",
    "**Cal Poly Email:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Assignment**:\n",
    "\n",
    "1. Complete the code for the Naive Bayes Classifier\n",
    "2. Complete the training and testing of the Classifier\n",
    "3. Compute the accuracy of the classifier and output the overall accuracy and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2023-12-07T22:55:31.115830500Z",
     "start_time": "2023-12-07T22:55:31.036742100Z"
    }
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**estimateNBModel**: function to produce all parameter estimates for the Naive Bayes model.\n",
    "\n",
    "This function returns two structures: an array of class probabilities P(Class = c_i),\n",
    "and a collection of \n",
    "$$P(A_j = a_k|Class = c_i)$$\n",
    "probability estimators for the probability that an observed record from class $c_i$ will take the value $a_k$ for its $j$th attribute $A_j$.\n",
    "\n",
    "The latter collection is stored as a list model[0..nClasses-1], where each model[i] is itself a list of length nAttributes of probability distributions over the values of each attribute.\n",
    "\n",
    "\n",
    "Input parameters for estimateNBModel():\n",
    "\n",
    "data: training set data points\n",
    "\n",
    "labels: labels for the training set data\n",
    "\n",
    "nAttributes: number of attributes in the dataset\n",
    "\n",
    "attributeRanges: number of unique values each attribute takes\n",
    "\n",
    "nClasses: number of classes (class labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Task** :   write the getClassProbability() function that given\n",
    "   \n",
    "   * the list of labels (labels) of the training set\n",
    "\n",
    "   * the class label (classId),\n",
    "   \n",
    "   * and the total number of classes in the dataset (nClasses)\n",
    "   \n",
    " returns the probability estimate for $P(Class = classId)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T22:49:57.778927800Z",
     "start_time": "2023-12-07T22:49:57.763073300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2023-12-07T22:57:43.515474700Z",
     "start_time": "2023-12-07T22:57:43.502960400Z"
    }
   },
   "outputs": [],
   "source": [
    "def getClassProbability(labels, classId,nClasses):\n",
    "    return (labels == classId).sum() / len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Task**: write the getNBEstimate() function that given\n",
    "\n",
    "* the training set (data)\n",
    "\n",
    "* the class labels for the training set (labels)\n",
    "\n",
    "* the class label for which the estimate is being produced (classLabel)\n",
    "\n",
    "* the attribute for which the estimate is being produced (attId)\n",
    "\n",
    "* the attribute value for which the estimate is being produced (attValue)\n",
    "\n",
    "* and the total number of values attribute attId has (nValues)\n",
    "\n",
    "produces the probability estimate for $P(A_{attId} = attValue | Class = classLabel)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2023-12-07T22:59:43.608064100Z",
     "start_time": "2023-12-07T22:59:43.601479900Z"
    }
   },
   "outputs": [],
   "source": [
    "def getNBEstimate(data, labels, classLabel, attId, attValue, nValues):\n",
    "    return ((data[: ,attId] == attValue) * (labels == classLabel)).sum() / (labels == classLabel).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-12-07T22:59:11.965525300Z",
     "start_time": "2023-12-07T22:59:11.959203800Z"
    }
   },
   "outputs": [],
   "source": [
    "def estimateNBModel(data, labels, nAttributes, attributeRanges, nClasses ):\n",
    "    ## Naive Bayes Model consists of two types of estimators\n",
    "    \n",
    "    ## First, we estimate the probability of seeing an object from a specific class\n",
    "    \n",
    "    classProbabilities = [getClassProbability(labels,l, nClasses) for l in range(nClasses)]\n",
    "    \n",
    "    ## now we estimate the probabilities of seeing a specific value of a specific attribute in\n",
    "    ## a data point from a given class\n",
    "    \n",
    "    ## for each class create the appropriate estimates\n",
    "    model = []                  # model is the list of estimates for all classes\n",
    "    for i in range(nClasses):   # for each class\n",
    "        ## for each attribute\n",
    "        classDistr = []         # classDistr is the collection of estimates for one class\n",
    "        for j in range(nAttributes):\n",
    "            estimates = []                    # estimates is a distribution of estimates for a single attribute\n",
    "            for k in range(attributeRanges[j]):\n",
    "                est = getNBEstimate(data, labels, i,j,k, attributeRanges[j])\n",
    "                estimates.append(est)\n",
    "            classDistr.append(estimates)\n",
    "        model.append(classDistr)\n",
    "    \n",
    "    return classProbabilities, model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicting The Class**\n",
    "\n",
    "function predictNBLabels() predicts the class labels for all data points in the test set.\n",
    "\n",
    "function predictNB() computes the probability estimates for each class and selects the class with the highest estimate for a single data point\n",
    "\n",
    "function predictNBClass computes the probability estimate for a specific class.\n",
    "\n",
    "**Your Task**: implement predictNBClass()\n",
    "\n",
    "its parameters are:\n",
    "\n",
    "* point: the data point for which the estimate is given\n",
    "\n",
    "* classProb:  the class probability P(Class = classID) for the class \n",
    "\n",
    "* classModel: the portion of the Naive Bayes model related to predicting this particular class\n",
    "\n",
    "(note that class label is not passed, but all proper values are selected in predictNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2023-12-07T23:04:36.064526400Z",
     "start_time": "2023-12-07T23:04:36.033769800Z"
    }
   },
   "outputs": [],
   "source": [
    "def predictNBClass(point, classProb, classModel):\n",
    "    jointProb = 1\n",
    "    for attr, val in enumerate(point):\n",
    "        jointProb = jointProb * classModel[int(attr)][int(val)]\n",
    "    return classProb * jointProb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictNB()  and predictNBLabels() parameters\n",
    "\n",
    "point: data point\n",
    "\n",
    "classProbabilities: the list of $P(Class = c_i)$ estimates\n",
    "\n",
    "model: the collection of $P(A_j = a_k |Class = c_i)$ probability estimates\n",
    "\n",
    "nClasses: number of class labels in the dataset\n",
    "\n",
    "You do not need to touch this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-12-07T23:04:00.933554100Z",
     "start_time": "2023-12-07T23:04:00.899069100Z"
    }
   },
   "outputs": [],
   "source": [
    "def predictNB(point, classProbabilities, model,nClasses):\n",
    "    \n",
    "    predictions= np.array([predictNBClass(point, classProbabilities[i],model[i]) for i in range(nClasses)])\n",
    "    \n",
    "    predictedClass = np.argmax(predictions)\n",
    "    return predictedClass\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2023-12-07T23:04:02.637423500Z",
     "start_time": "2023-12-07T23:04:02.627574100Z"
    }
   },
   "outputs": [],
   "source": [
    "def predictNBLabels(data, classProbabilities, model, nClasses):\n",
    "    predicted = [predictNB(point, classProbabilities, model, nClasses) for point in data]\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load Data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-12-07T23:04:05.950539300Z",
     "start_time": "2023-12-07T23:04:05.945791900Z"
    }
   },
   "outputs": [],
   "source": [
    "filename=\"data8.csv\"\n",
    "\n",
    "rawData = np.loadtxt(filename, delimiter = \",\")\n",
    "\n",
    "## let's keep only the two columns with the data attributes\n",
    "\n",
    "nAttributes = rawData.shape[1] - 1\n",
    "\n",
    "data = rawData[:,0:nAttributes]\n",
    "labels = rawData[:,nAttributes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[2., 0., 2., 3., 0., 0.],\n       [0., 1., 0., 1., 2., 2.],\n       [2., 0., 0., 3., 3., 2.],\n       ...,\n       [1., 2., 1., 1., 0., 0.],\n       [3., 0., 2., 3., 3., 1.],\n       [2., 0., 2., 1., 1., 1.]])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T23:04:07.838129300Z",
     "start_time": "2023-12-07T23:04:07.826979200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train the Model**\n",
    "\n",
    "In the cells below the entire dataset  is used to train the model. \n",
    "\n",
    "This allows us to see the predictions, but this is not a fair way to evaluate the quality of prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-12-07T23:04:09.457728200Z",
     "start_time": "2023-12-07T23:04:09.441567200Z"
    }
   },
   "outputs": [],
   "source": [
    "### Let us compute how many unique values each attribute has.\n",
    "### all attributes have values 0,1,.., k-1 where k is the number of unique values for that attribute.\n",
    "\n",
    "attributeRanges= [np.unique(data[:,i]).shape[0] for i in range(nAttributes)]\n",
    "\n",
    "## number of classes\n",
    "\n",
    "nClasses = np.unique(labels).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-12-07T23:04:11.298425400Z",
     "start_time": "2023-12-07T23:04:11.279521600Z"
    }
   },
   "outputs": [],
   "source": [
    "d,m = estimateNBModel(data,labels,nAttributes, attributeRanges,nClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-12-07T23:04:39.783350300Z",
     "start_time": "2023-12-07T23:04:39.761134200Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted = predictNBLabels(data,d,m,nClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "An easy way to see where we missed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2023-12-07T23:04:41.497659500Z",
     "start_time": "2023-12-07T23:04:41.476864100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0., -2.,  0.,\n        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n        0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,\n       -2.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n        0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n        0.,  1., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,\n        0.,  0., -2.,  1.,  0.,  0.,  1., -1.,  0.,  0.,  0.,  0., -1.,\n        0., -1.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,\n        0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,  0.,  0.,\n        0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0., -2.,\n        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n       -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n       -1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n        0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n        0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,\n        0.,  0., -1.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n        0., -2.,  1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n        0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0., -2.,  0.,\n        0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,  0.,  0.,  1.,\n        0.,  0.,  0.,  2.,  1.,  0.,  0., -2.,  0.,  0.,  0.,  0.,  1.,\n        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,\n        0.])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted - labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Task**:\n",
    "\n",
    "Split your dataset into the training set (2/3 of the data = 200 data points) and the test set (the remaining 1/3 of the data points = 100 points). Select your points at random, but make it reproducible by setting the seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2023-12-07T23:18:16.816149600Z",
     "start_time": "2023-12-07T23:18:16.788816900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hsu_m\\anaconda3\\envs\\csc466\\lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "split_3 = np.array_split(pd.DataFrame(data).sample(frac=1), 3)\n",
    "train = pd.concat(split_3[0:2])\n",
    "train_idx = list(train.index)\n",
    "train = train.to_numpy()\n",
    "test = split_3[1]\n",
    "test_idx = list(test.index)\n",
    "test = test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Your Task**: train the model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2023-12-07T23:18:19.531509900Z",
     "start_time": "2023-12-07T23:18:19.515877900Z"
    }
   },
   "outputs": [],
   "source": [
    "d_train, m_train = estimateNBModel(train,labels[train_idx],nAttributes,attributeRanges,nClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Your Task**: evaluate the model on the test set. Retrieve the predicted labels for the test set data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2023-12-07T23:19:53.253307300Z",
     "start_time": "2023-12-07T23:19:53.205783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 2, 0, 1, 2, 1, 2, 0, 1, 1, 2, 0, 1, 2, 2, 0, 0, 2, 1, 2, 2, 2,\n       1, 1, 0, 2, 2, 0, 0, 0, 1, 2, 2, 1, 0, 0, 2, 2, 0, 1, 0, 1, 0, 1,\n       0, 0, 1, 2, 0, 2, 1, 0, 0, 2, 2, 0, 2, 0, 1, 2, 0, 1, 2, 1, 1, 1,\n       2, 2, 0, 2, 0, 1, 2, 2, 1, 0, 0, 2, 0, 1, 1, 2, 2, 0, 0, 1, 1, 2,\n       1, 2, 1, 0, 0, 0, 0, 2, 0, 0, 2, 2], dtype=int64)"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = predictNBLabels(test,d,m,nClasses)\n",
    "test_pred = np.array(test_pred)\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Your Task**: compute the predictive accuracy on the training set and report it. \n",
    "\n",
    "Compute the predictive accuract on the test set and report it.\n",
    "\n",
    "Is there any evidence that the model overfits? (put a note in a markdown cell0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2023-12-07T23:22:03.519593700Z",
     "start_time": "2023-12-07T23:22:03.488224200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.83"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_pred == labels[test_idx]).sum() / len(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "0.835"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred = predictNBLabels(train,d,m,nClasses)\n",
    "train_pred = np.array(train_pred)\n",
    "(train_pred == labels[train_idx]).sum() / len(train_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T06:36:46.567832600Z",
     "start_time": "2023-12-08T06:36:46.547748700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the overfit question here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Task**: compute and output the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2023-12-08T06:55:58.610476800Z",
     "start_time": "2023-12-08T06:55:58.576981300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "obs   0.0  1.0  2.0\npred               \n0      30    1    5\n1       2   25    1\n2       2    6   28",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>obs</th>\n      <th>0.0</th>\n      <th>1.0</th>\n      <th>2.0</th>\n    </tr>\n    <tr>\n      <th>pred</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>25</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>6</td>\n      <td>28</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(pd.Series(test_pred, name=\"pred\"), pd.Series(labels[test_idx], name=\"obs\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations!** Your are done.\n",
    "\n",
    "Download the notebook, and submit it using the \n",
    "\n",
    "        handin dekhtyar 446-test <file>\n",
    " command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
